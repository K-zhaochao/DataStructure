# 第一章 绪论

在计算机科学的宏大图景中，《数据结构与算法》这一门课处于绝对的“内核”地位。如果说编程语言是建筑工具，那么数据结构就是结构力学与建筑图纸。在绪论中，我们要解决三个元问题：**我们要处理什么（对象）、如何处理（操作）、以及如何评价处理得好不好（评估）。**

---

### 第一部分：数据的二重性——逻辑与物理的剥离

初学者最容易混淆的，是“数据是什么样子的”和“数据在内存里是怎么存的”。这一章必须建立起 **抽象（Abstraction）** 的思维。

#### 1. 逻辑结构：对现实世界的建模

当我们面对一个非数值计算问题（如棋局推演、地图导航、组织架构）时，首先要剥离具体内容，提取元素之间的**关系**。这就是逻辑结构。

* **线性结构（Linear）**：表现为“一对一”的序列关系。如排队、书单。
* **树形结构（Tree）**：表现为“一对多”的层级关系。如族谱、文件系统。
* **图状结构（Graph）**：表现为“多对多”的网状关系。如社交网络、交通图。

#### 2. 存储结构：在计算机内的投影

逻辑结构是完美的数学模型，但计算机内存是线性的（地址从 0 到 N）。如何将复杂的逻辑结构“塞”进线性的内存中？主要有两种映射方案：

* **顺序存储（Sequential）**：利用内存的物理连续性来表达逻辑相邻。
  * *特点*：紧凑，但在中间插入或删除元素时由于需要移动数据，成本极高。
* **链式存储（Linked）**：利用指针（Pointer）来显式指示逻辑相邻。
  * *特点*：灵活，内存不连续，但需要额外的空间存储指针。

> **教学批注**：逻辑结构与存储结构是多对多的关系。一个逻辑上的“线性表”，既可以物理上实现为“顺序表（数组）”，也可以实现为“链表”。**逻辑决定了你能做什么，存储决定了你怎么做以及做得有多快。**

---

### 第二部分：工程化的雏形——抽象数据类型（ADT）

我们在定义一个数据结构时，不能只谈数据，不谈操作。
**抽象数据类型（ADT）** 是现代面向对象编程（OOP）的理论基石。它将数据结构定义为一个三元组：
$$ \text{ADT} = (D, S, P) $$

* $D$（Data）：数据对象。
* $S$（Relation）：数据关系。
* $P$（Operation）：基本操作集。

**核心价值**：**封装与隐藏**。
使用者只需要知道操作的接口（Interface），例如 `Add(x, y)` 或 `Find(x)`，而无需关心其内部是用数组还是链表实现的。这为大型软件系统的解耦提供了可能。

---

### 第三部分：算法效率的度量——渐进分析

这是本章最硬核、也是唯一的计算型考点。
我们如何评价一个算法的好坏？不能靠“跑一下”看几秒（那是事后统计，受硬件影响太大），而要进行**事前分析**。

我们采用 **大 $\mathcal{O}$ 表示法（Big O Notation）**，它衡量的不是具体时间，而是**当问题规模 $n$ 趋近于无穷大时，执行步骤的增长趋势**。

这里我有两个经典的案例，用来打破你的直觉：

#### 案例一：非线性的循环控制

很多人看到循环就认为是 $\mathcal{O}(n)$，这是错的。请看以下逻辑：

```c
x = 0;
while (n >= (x+1)*(x+1)) {
    x = x + 1;
}
```

**分析**：
循环的终止条件并非线性增长，而是由 `(x+1)^2` 逼近 `n`。
当 $(x+1)^2 \approx n$ 时，循环停止。
即 $x \approx \sqrt{n}$。
因此，该算法的时间复杂度为：
$$ T(n) = \mathcal{O}(\sqrt{n}) $$

#### 案例二：级数求和的嵌套循环

对于多重循环，不能简单地数层数，而要看基本操作的总执行次数。

```c
for (i = 1; i <= n; i++) {
    for (j = 1; j <= i*i; j++) {
        // 基本操作
        X = X + 1; 
    }
}
```

**分析**：
内层循环的执行次数是 $i^2$，且 $i$ 是变化的。我们需要对每一次外层循环的负载进行求和：
$$ f(n) = \sum_{i=1}^{n} i^2 = 1^2 + 2^2 + \dots + n^2 $$
根据数学中的平方和公式（Pyramidal Number）：
$$ \sum_{i=1}^{n} i^2 = \frac{n(n+1)(2n+1)}{6} $$
展开分子，最高次项为 $2n^3$。在渐进分析中，我们忽略系数和低次项：
$$ T(n) = \mathcal{O}(n^3) $$

> **避坑指南**：在计算空间复杂度 $S(n)$ 时，必须明确一点——它仅指**辅助空间**。输入数据本身占用的空间是不算在内的。如果你的算法只是对数组进行原地排序，无论数组多大，辅助空间是常数级，即 $S(n) = \mathcal{O}(1)$。

---

### 总结

第一章搭建了我们后续学习的框架：

1. 我们通过**逻辑结构**定义问题。
2. 我们通过**存储结构**在计算机中实现它。
3. 我们通过**时间复杂度**来评估我们的实现是否高效。

---

# 第二章 线性表

如果在上一章我们还在谈论空泛的哲学（逻辑结构），那么这一章我们将正式开始搬砖（存储实现）。线性表是所有复杂数据结构的基础，学好了它，后面的栈、队列、甚至树和图的遍历，你都能看到它的影子。

简单来说，线性表就是**排队**。数据元素一个挨着一个，除了头和尾，每个人都有一个“前任”和一个“现任”。

本章我们主要解决一个核心矛盾：**连续的内存（数组）虽好，但不够灵活；分散的内存（链表）灵活，但管理麻烦。** 我们将用 C++ 的类（Class）来封装这两者。

---

### 2.1 线性表的两种“肉体”

逻辑上它们都是线性的，但在物理内存中，它们有两种截然不同的生存形态。

#### 形态一：顺序表 (Sequential List)

这是线性表的**数组**形态。

* **特点**：内存地址连续，“邻居”就是物理上的邻居。
* **优点**：**随机存取**。想找第 $i$ 个人？直接计算地址 `base + i*size`，时间复杂度 $\mathcal{O}(1)$。
* **缺点**：**插入和删除太累**。想在队伍中间插个人，后面的人都得往后挪；想走个人，后面的人都得往前补。时间复杂度 $\mathcal{O}(n)$。

#### 形态二：链表 (Linked List)

这是线性表的**指针**形态。

* **特点**：内存地址分散，通过指针（Pointer）手拉手。
* **优点**：**插入删除极快**。只需要修改指针指向，不需要移动数据，$\mathcal{O}(1)$（前提是你已经找到了位置）。
* **缺点**：**不支持随机存取**。想找第 $i$ 个人？必须从头开始数，时间复杂度 $\mathcal{O}(n)$。

---

### 2.2 顺序表：高阶数组的封装

我们不能直接扔给用户一个裸数组，我们需要封装一个类 `SeqList`。这里要注意，由于不能用 STL 的 `vector`，我们需要自己管理动态内存。

#### 类定义框架

```cpp
using namespace std;

const int defaultSize = 100;

template <class T>
class SeqList {
protected:
    T *data;       // 动态数组指针
    int maxSize;   // 数组最大容量
    int last;      // 最后一个元素的下标（注意：不是长度，是下标，长度是 last+1）

public:
    SeqList(int sz = defaultSize);
    ~SeqList() { delete[] data; }
  
    int Length() const { return last + 1; }
    int Search(T x) const;        // 查找值 x 的位置
    bool Insert(int i, T x);      // 在第 i 个位置插入 x
    bool Remove(int i, T& x);     // 删除第 i 个位置，并把被删的值带回来
    // ... 其他接口
};
```

#### 核心难点：插入与删除的“搬运”

大家在写代码时最容易犯错的是循环的**边界**。

**插入操作（Insert）**：
要把元素 $x$ 插到第 $i$ 个位置（下标为 $i-1$），我们需要把从最后一名到第 $i$ 名的所有人往后挪一步。**注意：必须从后往前挪！**

```cpp
template <class T>
bool SeqList<T>::Insert(int i, T x) {
    if (last == maxSize - 1) return false; // 表满了
    if (i < 1 || i > last + 2) return false; // 位置非法（可以是 last+2，即插在队尾）

    // 元素后移，空出下标 i-1 的位置
    // j 是数组下标
    for (int j = last; j >= i - 1; j--) {
        data[j + 1] = data[j];
    }

    data[i - 1] = x; // 填入新值
    last++;          // 维护 last 指针
    return true;
}
```

**删除操作（Remove）**：
删除下标 $i-1$ 的元素，需要把后面的人往前挪。**注意：必须从前往后挪！**

```cpp
template <class T>
bool SeqList<T>::Remove(int i, T& x) {
    if (last == -1) return false; // 表空
    if (i < 1 || i > last + 1) return false;

    x = data[i - 1]; // 保存被删数据（这一步很重要，通常业务需要知道删了谁）

    // 元素前移
    for (int j = i; j <= last; j++) {
        data[j - 1] = data[j];
    }

    last--; 
    return true;
}
```

---

### 2.3 单链表：指针的艺术

链表是 C++ 数据结构的第一个分水岭。理解了**头结点（Head Node）**，你就理解了一半。

**为什么我们需要头结点？**
如果不带头结点，第一个结点的处理逻辑和其他结点不一样（因为没有前驱）。为了代码统一，我们人为地在链表最前面加一个“哨兵”，它的数据域为空，指针域指向真正的第一个元素。

#### 结点与链表类定义

```cpp
template <class T>
struct LinkNode {
    T data;
    LinkNode<T> *link;
    LinkNode(LinkNode<T> *ptr = NULL) { link = ptr; }
    LinkNode(const T& item, LinkNode<T> *ptr = NULL) { data = item; link = ptr; }
};

template <class T>
class List {
protected:
    LinkNode<T> *first; // 头指针，指向头结点

public:
    List() { first = new LinkNode<T>; } // 构造函数建立头结点
    ~List(); // 析构一定要遍历删除，否则内存泄漏
  
    bool Insert(int i, T x);
    bool Remove(int i, T& x);
    // ... 其他接口
};
```

#### 核心操作：断链与重连

在链表中，任何操作都依赖于**前驱结点**。如果你想在第 $i$ 个位置搞事情，你必须先找到第 $i-1$ 个结点。

**插入操作（Insert）**：
假设 `current` 指向第 $i-1$ 个结点，我们要插入新结点 `newNode`。
**口诀：先连后断。** 先让新人拉住后面的人，再让前面的人拉住新人。

```cpp
// 核心逻辑片段
LinkNode<T> *newNode = new LinkNode<T>(x);

newNode->link = current->link; // 1. 新结点指向原后续结点
current->link = newNode;       // 2. 前驱结点指向新结点
```

*如果反过来写，`current->link` 先被覆盖，后面的一整串链表就丢了（内存泄漏）。*

**删除操作（Remove）**：
同样，找到前驱 `current`，要删掉的是 `delNode` (即 `current->link`)。

```cpp
// 核心逻辑片段
LinkNode<T> *delNode = current->link;

current->link = delNode->link; // 前驱直接越过被删结点，指向下下个
T val = delNode->data;         // 保存数据
delete delNode;                // 别忘了释放内存！C++没有GC
```

#### 建表的两种流派

1. **前插法（头插法）**：新来的人总是插在头结点后面。
    * 结果：读入顺序 `1, 2, 3`，链表顺序 `3, 2, 1`。**逆序**。
2. **后插法（尾插法）**：新来的人插在最后。
    * 结果：顺序一致。**需要额外维护一个尾指针 `rear`**，否则每次都要从头跑到尾，效率太低。

---

### 2.4 链表的进化形态

#### 1. 循环链表 (Circular Linked List)

* **变化**：最后一个结点的 `link` 不指向 `NULL`，而是指向**头结点**。
* **判断结束**：`p->link != first`。
* **妙用**：约瑟夫环问题（丢手绢），或者合并两个链表时（只需把尾巴连到另一个头，时间 $\mathcal{O}(1)$）。

#### 2. 双向链表 (Doubly Linked List)

* **变化**：每个结点有两个指针：`llink` (左/前) 和 `rlink` (右/后)。
* **优势**：删除操作简化。不需要专门找前驱了，因为 `p->llink` 就是前驱。
* **代价**：空间换时间。
* **操作核心**：插入和删除时需要修改**四个指针**（或者两个方向的链接）。

**双链表删除结点的指针修复（假设删 `p`）：**

```cpp
// 假设 p 不是头尾特殊结点
p->llink->rlink = p->rlink; // p的前驱的右手指项p的后继
p->rlink->llink = p->llink; // p的后继的左手指向p的前驱
delete p;
```

---

### 2.5 经典应用：一元多项式加法

为什么用链表存多项式？
对于 $P(x) = 1 + 3x^{10000}$，如果用数组，你需要开一个长度 10001 的数组，中间全是 0，极其浪费。用链表只需存两个结点：`(1, 0)` 和 `(3, 10000)`。

**算法思路（归并思想）**：
有两个多项式链表 $A$ 和 $B$，按指数从小到大排列。我们定义两个指针 `pa`, `pb`。

1. 如果 `pa->exp < pb->exp`：`pa` 的项小，放入结果，`pa` 后移。
2. 如果 `pa->exp > pb->exp`：`pb` 的项小，放入结果，`pb` 后移。
3. 如果 `pa->exp == pb->exp`：指数相同，**系数相加**。
    * 如果和不为 0：放入结果。
    * 如果和为 0：抵消了，两边都后移，不存入结果。

---

作为这一章的总结，我要提醒你几个在考场中容易翻车的点：

1. **时间复杂度辨析**：
    * 访问第 $i$ 个元素：顺序表 $\mathcal{O}(1)$，链表 $\mathcal{O}(n)$。
    * 在已知位置插入/删除：顺序表 $\mathcal{O}(n)$，链表 $\mathcal{O}(1)$。
    * *注意*：题目如果问“在第 $i$ 个位置插入”，链表也是 $\mathcal{O}(n)$，因为查找第 $i$ 个位置需要时间。

2. **指针操作顺序**：永远记得“保留后路”。在修改当前指针指向别处之前，确保链表后半段的地址已经被新的指针（或临时变量）保存住了。

3. **就地逆置**：
    * 这是一个经典算法题。不要申请新链表。
    * 思路：把头结点摘下来，剩下的结点一个一个取下来，用**头插法**重新插回头结点后面。

---

# 第三章 栈和队列

在数据结构的江湖里，栈（Stack）和队列（Queue）被称为**受限的线性表**。什么叫“受限”？就是不准你随便插队，也不准你随便从中间抽人。所有的进出，都有严格的规矩。

这一章我们不仅要手写这两个容器，更要理解它们背后解决的核心问题：**顺序的可逆性与缓冲**。

---

### 3.1 栈 (Stack)：后进先出的哲学

**核心定义**：
栈是一个**LIFO (Last In First Out)** 结构。
想象你在洗盘子，洗好的盘子一个接一个往上摞（Push），取用的时候只能拿最上面的（Pop）。或者想象给手枪弹夹装子弹，最先压进去的子弹，最后才能打出来。

栈主要涉及两个指针/变量：

* **栈底 (Bottom)**：通常是固定的。
* **栈顶 (Top)**：随着元素的进出上下浮动。

#### 3.1.1 顺序栈 (Sequential Stack)

用数组来实现栈是最自然的。

**设计痛点**：`top` 指针到底指向哪里？

* *流派 A*：`top` 指向栈顶元素本身。初始化 `top = -1`。
* *流派 B*：`top` 指向栈顶元素的**下一个**空位置。初始化 `top = 0`。
* **课件标准**：依据你的课件，我们采用**流派 A (`top = -1`)**。

**类定义实现**：

```cpp
template <class T>
class SeqStack {
private:
    T *elements;    // 动态数组
    int top;        // 栈顶指针（下标）
    int maxSize;    // 最大容量

    void overflowProcess(); // 扩容处理（私有，不对外暴露）

public:
    SeqStack(int sz = 50);
    ~SeqStack() { delete[] elements; }

    bool Push(const T& x); // 进栈
    bool Pop(T& x);        // 出栈
    bool GetTop(T& x);     // 偷看一眼栈顶
    bool IsEmpty() const { return top == -1; }
    bool IsFull() const { return top == maxSize - 1; }
};
```

**关键操作代码**：

```cpp
// 进栈 Push
template <class T>
bool SeqStack<T>::Push(const T& x) {
    if (IsFull()) overflowProcess(); // 满了就扩容
  
    top++; // 先让指针往上移
    elements[top] = x; // 再放数据
    return true;
}

// 出栈 Pop
template <class T>
bool SeqStack<T>::Pop(T& x) {
    if (IsEmpty()) return false;
  
    x = elements[top]; // 先取数据
    top--; // 指针下移（逻辑删除，物理数据还在但无效了）
    return true;
}
```

#### 3.1.2 链式栈 (Linked Stack)

链式栈本质上就是一个**只能在头部插入和删除的单链表**。

* `top` 指针就是链表的 `head` 指针。
* **优势**：永远不会满（除非内存耗尽），不需要扩容逻辑。

```cpp
template <class T>
struct StackNode {
    T data;
    StackNode<T> *link;
    StackNode(T d, StackNode<T> *l = NULL) : data(d), link(l) {}
};

template <class T>
class LinkedStack {
private:
    StackNode<T> *top; // 相当于链表的 head

public:
    LinkedStack() : top(NULL) {}
    ~LinkedStack(); // 析构时需要遍历删除所有结点
  
    void Push(T x) {
        top = new StackNode<T>(x, top); // 新结点的 next 指向旧 top，新 top 变成新结点
    }

    bool Pop(T& x) {
        if (top == NULL) return false;
        StackNode<T> *p = top;
        x = p->data;
        top = top->link; // top 指针下移
        delete p;        // 释放内存
        return true;
    }
};
```

---

### 3.2 栈的硬核应用

为什么计算机离不开栈？因为**函数调用（Function Call）**和**递归（Recursion）**本质就是栈。

#### 1. 递归的消除

课件中提到了阶乘 $n!$。递归之所以能工作，是因为系统帮你维护了一个隐形的“栈”，保存了每一层调用的参数和返回地址。
如果你想把递归代码改成非递归（迭代），通常需要自己手动维护一个栈。

#### 2. 括号匹配 (Parenthesis Matching)

这是面试高频题。

* 遇到左括号 `(`, `[`, `{` $\rightarrow$ **入栈**。
* 遇到右括号 `)`, `]`, `}` $\rightarrow$ **检查栈顶**。
  * 如果栈空：报错（右括号多了）。
  * 如果栈顶不匹配：报错（类型不对，比如 `(]`）。
  * 如果匹配：**出栈**（消掉一对）。
* 最后：栈必须为空，否则说明左括号多了。

#### 3. 表达式求值 (Expression Evaluation)

人类习惯看**中缀表达式**（如 `4 + 2 * 3`），但计算机喜欢**后缀表达式**（Reverse Polish Notation，如 `4 2 3 * +`）。

* **原理**：后缀表达式不需要括号，也不需要考虑优先级，读到一个运算符，就从栈里弹出两个数字计算，结果压回栈里。

---

### 3.3 队列 (Queue)：先进先出的秩序

**核心定义**：
队列是一个**FIFO (First In First Out)** 结构。
就像排队做核酸，先来的人先捅。

* **队尾 (Rear)**：只允许在这里插入（EnQueue）。
* **队头 (Front)**：只允许在这里删除（DeQueue）。

#### 3.3.1 顺序队列的“假溢出”危机

如果我们用普通数组 `data[0...n]` 做队列：

* 入队：`rear++`
* 出队：`front++`

**问题来了**：随着队伍不断移动，`front` 和 `rear` 都会一直向后跑。当 `rear` 跑到数组尽头时，哪怕 `front` 前面已经空出了大量位置（人都走光了），我们也无法利用。这叫**假溢出**。

#### 3.3.2 循环队列 (Circular Queue) —— 本章难点

为了解决假溢出，我们将数组看作一个首尾相接的圆环。
**数学魔法**：取模运算 `%`。

* 下标移动公式：`index = (index + 1) % maxSize`

**最大的坑：如何区分队空和队满？**
如果是环形的，当 `front == rear` 时，可能是空的，也可能是满的（跑了一圈追上来了）。

**解决方案（课件采用方案）**：
**牺牲一个存储单元**。即：队列永远留一个空位不存数据。

* **队空条件**：`front == rear`
* **队满条件**：`(rear + 1) % maxSize == front` （rear 再走一步就撞上 front 了）

**循环队列类实现**：

```cpp
template <class T>
class CirQueue {
private:
    T *elements;
    int front, rear;
    int maxSize;

public:
    CirQueue(int sz = 10);
    ~CirQueue() { delete[] elements; }

    bool EnQueue(const T& x);
    bool DeQueue(T& x);
  
    // 计算当前队列长度的公式（必考）
    int GetSize() const { 
        return (rear - front + maxSize) % maxSize; 
    }
};
```

**关键操作代码**：

```cpp
// 入队
template <class T>
bool CirQueue<T>::EnQueue(const T& x) {
    // 先判断满没满（牺牲一个格子的判满逻辑）
    if ((rear + 1) % maxSize == front) return false;
  
    elements[rear] = x;
    rear = (rear + 1) % maxSize; // 循环移动
    return true;
}

// 出队
template <class T>
bool CirQueue<T>::DeQueue(T& x) {
    if (front == rear) return false; // 队空
  
    x = elements[front];
    front = (front + 1) % maxSize; // 循环移动
    return true;
}
```

#### 3.3.3 链式队列

链式队列有两个指针 `front` 和 `rear`。

* **入队**：`rear->link = newNode; rear = newNode;`
* **出队**：`p = front; front = front->link; delete p;`
* **特判**：当队列中只有一个元素，出队后队列变空，记得**要把 `rear` 也修正为 `NULL`**（或者指向头结点，取决于带不带头结点），否则 `rear` 会变成悬空指针。

---

### 3.4 队列应用：杨辉三角

课件中提到的杨辉三角打印，利用了队列的**缓冲特性**。
第 $i$ 行的数据 `1, 3, 3, 1`，通过计算，产生第 $i+1$ 行的数据 `1, 4, 6, 4, 1`。

* 算法核心：从队列头部取出一个数 $t$，结合上一轮暂存的数 $s$，计算 $s+t$ 放入队尾。
* 这展示了队列作为**数据缓冲区 (Buffer)** 的作用——在生产者（计算逻辑）和消费者（打印逻辑）之间建立桥梁。

---

### 总结与避坑

1. **栈**：
    * 关注 `top` 的初始值。是 `-1` 还是 `0`？这决定了你是 `elements[++top]=x` 还是 `elements[top++]=x`。
    * 应用场景：逆序输出、递归、括号、后缀表达式。

2. **队列**：
    * **循环队列是重点**。牢记 `(rear + 1) % maxSize == front` 是判满条件，`rear == front` 是判空条件。
    * **计算长度**：千万别直接 `rear - front`，因为 `rear` 可能比 `front` 小（绕了一圈）。正确公式是 `(rear - front + maxSize) % maxSize`。

---

# 第四章 多维数组和广义表

这一章我们将视线从一维的“线”扩展到多维的“面”甚至更复杂的嵌套结构。

如果说线性表是一排平房，那么**多维数组**就是摩天大楼，而**广义表**则是俄罗斯套娃。这一章的核心不在于复杂的逻辑（像链表断链那样），而在于**计算**和**定义**。

我们需要解决两个核心问题：

1. **映射**：如何把多维的逻辑结构，拍扁了塞进一维的物理内存里？
2. **压缩**：如果数据中有大量重复或无效的值，如何省空间？

以下是我对这一领域的深度梳理。

---

### 第一部分：数组——从逻辑多维到物理一维

数组（Array）是最基础的线性结构扩展。在 C++ 中，我们既有静态的 `int a[2][3]`，也有动态的指针数组。

#### 1. 内存映射机制

计算机的内存地址是线性的（0, 1, 2...）。要存储二维数组 $A[m][n]$，我们必须约定一种**线性化（Linearization）** 的规则。

* **行序为主（Row-major Order）**：这也是 C++、Pascal 的默认规则。先存第一行，再存第二行……
* **列序为主（Column-major Order）**：Fortran 的规则。先存第一列，再存第二列……

#### 2. 寻址公式（必考点）

假设数组 $A$ 的起始地址为 $LOC(0, 0)$，每个元素占用 $L$ 个字节。我们需要计算元素 $A[i][j]$ 的地址。

**以行序为主（C++ 标准）：**
$$ LOC(i, j) = LOC(0, 0) + (i \times n + j) \times L $$

* **推导逻辑**：在你前面有 $i$ 个完整的行（每行 $n$ 个元素），在当前行你前面有 $j$ 个元素。

**注意坑点**：
考试时一定要看清**下标是从 0 开始还是从 1 开始**。

* 如果下标从 1 开始（$1 \dots m, 1 \dots n$）：
    $$ LOC(i, j) = LOC(1, 1) + [(i-1) \times n + (j-1)] \times L $$

---

### 第二部分：特殊矩阵的压缩存储

工程中经常遇到 huge 矩阵，但里面可能只有几个非零数，或者数据是对称分布的。直接开二维数组会造成极大的内存浪费（Memory Leak 的前兆）。我们需要**压缩存储**。

#### 1. 对称矩阵（Symmetric Matrix）

特点：$a_{ij} = a_{ji}$。我们只需要存储下三角（或上三角）。
将 $n \times n$ 的矩阵压缩到一维数组 $SA[k]$ 中。数组长度为 $\frac{n(n+1)}{2}$。

**映射关系（存储下三角，下标从0开始）：**
对于矩阵元素 $a_{ij}$（当 $i \ge j$ 时）：
$$ k = \frac{i(i+1)}{2} + j $$

* **解释**：第 $0$ 行有 1 个元素，第 $1$ 行有 2 个元素……第 $i-1$ 行有 $i$ 个元素。前 $i$ 行总共是等差数列求和。

#### 2. 三角矩阵

分为上三角和下三角。

* **特点**：一半空间存储元素，另一半全是常数 $c$（通常是 0）。
* **存储**：和对称矩阵一样，只是多分配一个空间存那个常数 $c$。

#### 3. 对角矩阵（带状矩阵）

特点：非零元素集中在主对角线附近。例如**三对角矩阵**，只有 $|i-j| \le 1$ 的地方有值。

* **公式推导**：第 0 行 2 个，第 $n-1$ 行 2 个，中间行都是 3 个。
* **通用公式（三对角）**：$k = 2i + j$ （具体常数项取决于下标起始点，需现场推导）。

---

### 第三部分：稀疏矩阵（Sparse Matrix）

当非零元素极少（比如稀疏因子 $\delta \le 0.05$）且分布无规律时，用上面的公式就没法算了。我们只需存储非零元素。

#### 1. 三元组顺序表 (Tuple List)

最简单的思路。把每个非零元素记为一个结构体：`(row, col, value)`。

```cpp
struct Triple {
    int i, j; // 行号，列号
    T e;      // 值
};
```

* **优点**：节省空间。
* **缺点**：无法随机存取。如果要找 $A[5][6]$，必须遍历整个表。

#### 2. 十字链表 (Cross-List)

这是链表的高级形态。每个非零节点既属于某一行的链表，也属于某一列的链表。

* **节点结构**：`{row, col, value, *down, *right}`
  * `right` 指针：指向同行的下一个非零元。
  * `down` 指针：指向同列的下一个非零元。
* **适用场景**：矩阵加法、乘法等频繁变动结构的运算。

---

### 第四部分：广义表（Generalized List）——递归的艺术

这是本章最抽象的概念。广义表是线性表的推广，区别在于：**线性表的元素只能是原子，广义表的元素既可以是原子，也可以是子表。**

表示为：$LS = (a_1, a_2, \dots, a_n)$

#### 1. 两个核心概念：表头与表尾

这是所有广义表操作的基础，也是极其容易混淆的概念。

* **表头 (Head)**：列表中的**第一个元素**。它可以是原子，也可以是子表。
* **表尾 (Tail)**：除去表头后，**剩下的元素组成的新表**。**注意：表尾一定是一个表！**

**经典案例分析**：
设 $L = (a, (b, c))$

* $Head(L) = a$ （因为 $a$ 是第一个元素）
* $Tail(L) = ((b, c))$ （除去 $a$ 后剩下 $(b, c)$，加个括号变成表）

设 $K = ((a, b))$

* $Head(K) = (a, b)$ （第一个元素是个子表）
* $Tail(K) = ()$ （除去第一个元素，后面没了，是空表）

#### 2. 广义表的性质

1. **层次性**：有深度。
2. **共享性**：子表可以被不同的广义表共享（类似图的结构）。
3. **递归性**：表可以包含其自身（如 $L = (a, L)$）。

---

### 总结与实战建议

这一章在编程实现上不如链表和树那么常见（除了稀疏矩阵在科学计算中），但在理论考试中是**计算题**的重灾区。

**备考重点：**

1. **地址计算**：给你一个 $A[10][20]$，基地址 1000，按列存储，求 $A[5][6]$ 的地址。这时候一定要画图！搞清楚是先算行还是先算列。
2. **压缩矩阵下标映射**：给你一个一维数组下标，问你对应矩阵的坐标 $(i, j)$，或者反过来。记住等差数列求和公式 $\frac{n(n+1)}{2}$。
3. **广义表 Head/Tail**：反复练习取表头表尾的操作。例如：从 $(a, b, (c, d))$ 中取出 $c$ 需要几次 Head/Tail 操作？
    * $Tail \to (b, (c, d))$
    * $Tail \to ((c, d))$
    * $Head \to (c, d)$
    * $Head \to c$
    * 答案：$Head(Head(Tail(Tail(L))))$。

---

# 第五章 树和二叉树

如果说线性表是一维的平原，那么树就是二维的山脉。在这里，数据不再是一个接一个地排队，而是层层递进，开枝散叶。

本章的知识密度极大，为了让你不迷失在这片森林里，我为你梳理了一份生存指南。我们重点攻克三个堡垒：**二叉树的核心性质、遍历算法、以及赫夫曼树（Huffman Tree）。**

---

### 5.1 树的基础认知

树（Tree）是 $n$ 个结点的有限集。

* **度（Degree）**：结点拥有的子树数。叶子结点的度为 0。
* **深度（Depth）/ 高度**：树的最大层次数。
* **有序树**：孩子结点从左到右是有次序的，不能互换。（二叉树是有序的）

---

### 5.2 二叉树（Binary Tree）—— 重中之重

二叉树不是树的特例，它是一种独立的逻辑结构。每个结点最多两个孩子，且必须分清**左孩子**和**右孩子**。

#### 核心性质（必考公式）

1. **第 $i$ 层结点数**：最多 $2^{i-1}$ 个。
2. **深度为 $k$ 的树总结点数**：最多 $2^k - 1$ 个（满二叉树）。
3. **叶子与度为2结点的关系**：对任何非空二叉树，$n_0 = n_2 + 1$。
    * *推导逻辑*：总度数 = $n - 1$（除了根，每个结点都有且仅有一个入边）。总度数又等于 $1 \times n_1 + 2 \times n_2$。联立方程即可得证。
4. **完全二叉树的父子关系**：如果给结点按层序编号（从1开始）：
    * 结点 $i$ 的左孩子是 $2i$。
    * 结点 $i$ 的右孩子是 $2i + 1$。
    * 结点 $i$ 的父亲是 $\lfloor i/2 \rfloor$。

#### 特殊形态

* **满二叉树**：每一层都塞满了，一个坑都不缺。
* **完全二叉树**：只有最后一层可以不慢，且叶子必须紧紧靠在左边。这是堆（Heap）的基础。

---

### 5.3 二叉树的存储与遍历

#### 1. 存储结构

* **顺序存储**：只适合完全二叉树（否则会浪费大量空间存空指针）。
* **链式存储（二叉链表）**：最常用。

    ```cpp
    struct BinTreeNode {
        T data;
        BinTreeNode *left, *right;
    };
    ```

#### 2. 遍历算法（递归与非递归）

遍历是所有二叉树算法的根基。必须熟练掌握递归写法，理解非递归逻辑。

* **前序（Pre-order）**：根 $\to$ 左 $\to$ 右
* **中序（In-order）**：左 $\to$ 根 $\to$ 右
* **后序（Post-order）**：左 $\to$ 右 $\to$ 根
* **层序（Level-order）**：从上到下，从左到右。**必须借助队列（Queue）实现。**

**经典考题：**
给出一棵树的前序序列和中序序列，请画出这棵树。

* *解题秘籍*：**前序找根，中序分左右。**
  * 前序第一个字母一定是根。
  * 去中序里找到这个根，根左边的是左子树，右边的是右子树。
  * 递归重复此过程。

#### 3. 线索二叉树（Threaded Binary Tree）

为了利用那些空着的 `NULL` 指针，我们将它们利用起来：

* 如果左指针为空，指向该结点的**前驱**。
* 如果右指针为空，指向该结点的**后继**。
* 这样就不需要递归或栈，就能直接遍历树了。

---

### 5.4 树与森林

普通树怎么存？

* **孩子兄弟表示法（Left-Child, Right-Sibling）**：
  * 每个结点两个指针：一个指向第一个孩子，一个指向下一个兄弟。
  * **魔法**：这实际上把任何普通树转化为了二叉树！
  * **口诀**：长子变左孩，兄弟变右孩。

**森林与二叉树的转换**：

* 森林 $\to$ 二叉树：把每棵树都转成二叉树，然后把根结点当成兄弟连起来（右斜线）。

---

### 5.5 赫夫曼树（Huffman Tree）与编码

这是二叉树最经典的压缩应用。

**定义**：**带权路径长度（WPL）** 最小的二叉树。

**构造算法（贪心策略）**：

1. 把所有权值看作森林中的孤立树。
2. **挑**：选出权值最小的两棵树。
3. **合**：造一个新根，权值为两棵树之和。新根作为那两棵树的爸爸。
4. **放**：把新根放回森林，删掉原来的两棵树。
5. 重复，直到只剩下一棵树。

**赫夫曼编码**：

* **前缀编码**：没有任何一个编码是另一个编码的前缀（例如，如果 A 是 0，那么 B 就不能是 01）。赫夫曼树天然满足这个性质，因为所有字符都在叶子上。
* **规则**：左分支记为 0，右分支记为 1。

---

### 总结与避坑

1. **递归的思维**：写二叉树代码时，不要试图人肉跟踪每一层递归。要相信你的函数能处理好子问题。例如求树高 `Height(T) = max(Height(L), Height(R)) + 1`。

2. **非递归遍历的难点**：
    * 前序和中序用**栈**比较好写。
    * 后序遍历非递归最难，因为根结点要第三次经过（左回、右回）才能访问，通常需要记录“上一次访问的结点”来判断是从左边回来的还是右边回来的。

3. **WPL 计算**：
    * 考试时有两种算发：
        1. $\sum (\text{叶子权值} \times \text{路径长度})$。
        2. **所有非叶子结点的权值之和**。这个方法通常更快！

---

# 第六章 图

这是数据结构中非常核心且难度较大的一章——**第六章：图 (Graph)**。

相比于线性表（一对一）和树（一对多），图处理的是**多对多**（任意两个节点都可能相关）的数据关系。这一章不仅概念繁多，而且算法非常经典且在实际应用中极高频。

以下是根据你提供的课件内容整理的核心知识点梳理，涵盖了定义、存储、遍历及四大核心应用算法。

---

### 6.1 图的定义与基本术语

#### 1. 基本定义

图 $G$ 由顶点集 $V$ 和边集 $E$ 组成，记为 $G=(V, E)$。

* **无向图**：边没有方向，表示为 $(v_1, v_2)$。$(v_1, v_2) = (v_2, v_1)$。
* **有向图**：边有方向（称为弧），表示为 $<v_1, v_2>$。$v_1$ 为弧尾，$v_2$ 为弧头。
* **网 (Network)**：带权的图（边上有数值，代表距离、耗费等）。

#### 2. 重要性质与公式

* **边的数量限制**：
  * 无向图：$0 \le e \le \frac{n(n-1)}{2}$。达到最大值时称为**完全图**。
  * 有向图：$0 \le e \le n(n-1)$。达到最大值时称为**有向完全图**。
* **度 (Degree)**：
  * 无向图：$TD(v)$ = 与 $v$ 相关联的边数。
  * 有向图：$TD(v) = ID(v) + OD(v)$ （入度 + 出度）。
* **握手定理**：所有顶点的度数之和等于边数的2倍。
    $$ \sum_{i=1}^{n} TD(v_i) = 2e $$

#### 3. 连通性

* **连通图 (无向)**：任意两个顶点之间都有路径。**连通分量**是无向图的极大连通子图。
* **强连通图 (有向)**：任意一对顶点 $v_i, v_j$，从 $v_i \to v_j$ 和 $v_j \to v_i$ 都有路径。

---

### 6.2 图的存储结构

图无法像数组那样物理连续存储，主要有两种存储方式：

| 存储方式 | 描述 | 空间复杂度 | 优缺点 |
| :--- | :--- | :--- | :--- |
| **邻接矩阵** (Adjacency Matrix) | 二维数组 `A[n][n]`。若有一条边 $(i, j)$，则 `A[i][j]=1` (或权值)；否则为 0 (或 $\infty$)。 | $O(n^2)$ | **优**：易判断两点是否直连，易求度。<br>**缺**：稀疏图时浪费空间。 |
| **邻接表** (Adjacency List) | 数组+链表。每个顶点有一个链表，挂着所有与它相邻的边。 | 无向：$O(n+2e)$<br>有向：$O(n+e)$ | **优**：节省空间（稀疏图），易找邻接点。<br>**缺**：不易判断两点是否直连，有向图求入度难（需逆邻接表）。 |

*其他结构*：**十字链表**（优化有向图求度）、**邻接多重表**（优化无向图边操作）。

---

### 6.3 图的遍历

遍历是后续复杂算法的基础。

#### 1. 深度优先搜索 (DFS)

* **思路**：类似于树的**先序遍历**。一条路走到黑，撞墙了再回溯。
* **实现**：通常使用**递归**或**栈**。
* **应用**：判断回路、求连通分量。

#### 2. 广度优先搜索 (BFS)

* **思路**：类似于树的**层次遍历**。先访问所有邻居，再访问邻居的邻居。
* **实现**：必须使用**队列**。
* **应用**：求无权图的最短路径。

---

### 6.4 最小生成树 (MST)

**目标**：在 $n$ 个顶点的连通网中，找 $n-1$ 条边，连通所有顶点且**权值之和最小**。

#### 1. Prim 算法 (普里姆)

* **策略**：**加点法**。从一个顶点开始，每次找连接“已选顶点集合”和“未选顶点集合”之间权值最小的边，将对应的点加入集合。
* **适用**：稠密图。

#### 2. Kruskal 算法 (克鲁斯卡尔)

* **策略**：**加边法**。将所有边按权值排序，从小到大选边。如果选的边会构成回路（即两个点已经在一个集合里），则丢弃；否则加入。
* **适用**：稀疏图。

---

### 6.5 最短路径

**目标**：在带权有向图中，求两个顶点间权值之和最小的路径。

#### 1. Dijkstra 算法 (迪杰斯特拉)

* **解决问题**：**单源**最短路径（从 $v_0$ 到其他所有点）。
* **思想**：贪心策略。按路径长度递增的次序产生最短路径。
* **公式**：
    $$ D[j] = \min \{ D[j], \ D[k] + \text{weight}(k, j) \} $$
    其中 $k$ 是新加入确定集合的中间点。

#### 2. Floyd 算法 (弗洛伊德)

* **解决问题**：**所有顶点对**之间的最短路径。
* **思想**：动态规划。逐步允许经过顶点 $0, 1, \dots, k$ 作为中间点来更新路径。
* **公式**：
    $$ D[i][j] = \min \{ D[i][j], \ D[i][k] + D[k][j] \} $$
* **复杂度**：$O(n^3)$。

---

### 6.6 有向无环图 (DAG) 的应用

DAG (Directed Acyclic Graph) 常用于工程规划。

#### 1. 拓扑排序 (AOV 网)

* **AOV (Activity On Vertex)**：顶点表示活动，边表示优先关系。
* **目标**：将所有顶点排成一个线性序列，使得若存在 $<v_i, v_j>$，则 $v_i$ 必在 $v_j$ 前面。
* **算法**：
    1. 找入度为 0 的顶点输出。
    2. 删除该顶点及其发出的边。
    3. 重复直到图空或这剩环。
* **应用**：检测图中是否有环；安排课程学习顺序。

#### 2. 关键路径 (AOE 网)

* **AOE (Activity On Edge)**：边表示活动（有持续时间），顶点表示事件。
* **关键路径**：从源点到汇点**路径长度最长**的路径。决定了整个工程的最短工期。
* **核心计算**：
  * **$Ve(i)$ 事件最早发生时间**：从前向后推，取最大值（必须等所有前驱活动做完）。
        $$ Ve(j) = \max \{ Ve(i) + \text{duration}(i, j) \} $$
  * **$Vl(i)$ 事件最迟发生时间**：从后向前推，取最小值（不能耽误后继活动）。
        $$ Vl(i) = \min \{ Vl(j) - \text{duration}(i, j) \} $$
  * **关键活动**：满足 $Ve = Vl$ 的活动（即没有空闲时间，必须准时开始）。

---

### 学习建议

1. **画图**：图的算法非常抽象，做题时一定要动手画图，模拟 Prim、Dijkstra 等算法的每一步过程。
2. **区分 AOV 和 AOE**：
    * AOV 重点在于**顺序**（拓扑排序）。
    * AOE 重点在于**时间/工期**（关键路径）。
3. **公式记忆**：握手定理、Dijkstra 的更新公式、关键路径的推导逻辑是必考点。

---

# 第九章 查找

这是数据结构中非常重要的一章——**查找 (Search)**。

查找是数据处理的核心操作之一，它的效率直接决定了系统的性能。这一章我们从最简单的线性查找开始，一路升级到树形查找，最后是用空间换时间的哈希查找。

以下是第九章的核心知识点梳理，涵盖了静态查找、动态查找（二叉排序树、平衡二叉树）以及哈希表。

---

### 9.1 静态查找 (Static Search)

静态查找表中，数据集合相对稳定，主要操作是检索。

#### 1. 顺序查找 (Sequential Search)

* **方法**：从头到尾一个一个比。
* **效率**：
  * 成功平均查找长度 (ASL)：$(n+1)/2$。
  * 时间复杂度：$O(n)$。
* **特点**：算法简单，对数据无序要求，但慢。

#### 2. 折半查找 / 二分查找 (Binary Search)

* **前提**：**必须是顺序存储的有序表**。
* **方法**：每次跟中间元素 `mid` 比。
  * 如果 `key < mid`，去左半边找 (`high = mid - 1`)。
  * 如果 `key > mid`，去右半边找 (`low = mid + 1`)。
* **判定树**：折半查找的过程可以用一棵二叉树来描述。树的深度决定了查找次数。
* **效率**：
  * 时间复杂度：$O(\log_2 n)$。
* **代码核心**（必背）：

    ```cpp
    while (low <= high) {
        mid = (low + high) / 2;
        if (key == a[mid]) return mid;
        else if (key < a[mid]) high = mid - 1;
        else low = mid + 1;
    }
    ```

---

### 9.2 动态查找 (Dynamic Search)

动态查找表在查找过程中可能进行插入或删除操作。

#### 1. 二叉排序树 (BST, Binary Sort Tree)

* **定义**：
  * 左子树所有节点 < 根节点。
  * 右子树所有节点 > 根节点。
* **性质**：**中序遍历**一棵 BST，可以得到一个有序序列。
* **查找效率**：取决于树的形状。
  * 最好情况（像完全二叉树）：$O(\log_2 n)$。
  * 最坏情况（退化成单支树/链表）：$O(n)$。

#### 2. 平衡二叉树 (AVL Tree)

为了防止 BST 退化成链表，引入了平衡机制。

* **定义**：任意节点的左右子树高度差（平衡因子 BF）的绝对值不超过 1。$|BF| \le 1$。
* **平衡调整（旋转）**：当插入节点导致失衡时，需要旋转。四种类型（口诀）：
  * **LL 型**：左子树的左边插入导致。**右单旋**。
  * **RR 型**：右子树的右边插入导致。**左单旋**。
  * **LR 型**：左子树的右边插入导致。**先左旋后右旋**。
  * **RL 型**：右子树的左边插入导致。**先右旋后左旋**。

---

### 9.3 哈希表 (Hash Table) / 散列表

这是查找速度最快的方法，理想情况下复杂度为 $O(1)$。它的核心思想是：**地址 = f(关键字)**。

#### 1. 哈希函数构造

目标是让地址分布均匀，减少冲突。

* **直接定址法**：$H(key) = a \times key + b$。适合关键字分布连续的情况。
* **除留余数法**（最常用）：$H(key) = key \ \% \ p$。
  * $p$ 的选择很重要，通常取**小于等于表长的最大质数**。
* **数字分析法**、**平方取中法**等。

#### 2. 处理冲突 (Collision Resolution)

当 $H(key_1) = H(key_2)$ 时，就发生了冲突。

* **开放定址法 (Open Addressing)**：这就好比这个坑被占了，我去下一个坑看看。
  * **线性探测**：$d_i = 1, 2, 3...$ （挨着往后找）。容易产生“堆积”现象。
  * **二次探测**：$d_i = 1^2, -1^2, 2^2, -2^2...$ （跳着找）。
* **链地址法 (Chaining)**：这就好比坑被占了，我就在这个坑上面盖楼（挂链表）。
  * 所有同义词存储在一个单链表中。

#### 3. 性能分析 (ASL 计算)

这是考试的计算题重灾区。

* **ASL 成功**：所有元素查找到所需比较次数的和 / 元素个数。
* **ASL 不成功**：查找失败时（通常是查找到空位置）所需比较次数的和 / 哈希函数可能的取值个数（即 $p$）。

**例题思路**：
给定关键字序列 `{19, 14, 23, 1}`，哈希函数 $H(k) = k \% 7$，表长 7。

* $19 \% 7 = 5$，放位置 5。（比较1次）
* $14 \% 7 = 0$，放位置 0。（比较1次）
* $23 \% 7 = 2$，放位置 2。（比较1次）
* $1 \% 7 = 1$，放位置 1。（比较1次）
* **ASL成功** = $(1+1+1+1)/4 = 1$。

如果发生冲突（比如线性探测），记得把探测次数累加。

---

### 总结与复习建议

1. **代码手写**：二分查找的代码必须滚瓜烂熟，边界条件 `low <= high` 容易写错。
2. **画图**：
    * 给你一个序列，画出生成的二叉排序树。
    * 给你一个失衡的 AVL 树，画出旋转后的结果。
3. **计算**：哈希表的 ASL 计算（成功与不成功）一定要亲自算几遍，特别是“不成功”时的分母是模数 $p$ 这一点经常被搞混。

---

# 第十章 排序

这是第十章《内部排序》的深度解析。为了让你更清晰地理解算法的执行流程，我将**核心算法原理**与**伪代码 (Pseudocode)** 结合讲解，并配合课件中的经典例子（如 `49, 38, 65...`）进行演示。

---

### 10.1 插入排序类 (Insertion Sort)

此类排序的核心思想是：**将一个记录插入到已排好序的有序表中**。

#### 1. 直接插入排序 (Direct Insertion Sort)

* **思路**：将数组分为“有序区”和“无序区”。初始时，第一个元素是有序区。每次从无序区取一个元素，在有序区中从后往前扫描，找到合适位置插入。
* **哨兵 (Sentinel)**：课件中提到的 `A[0]` 常作为哨兵（存待插元素），防止数组越界，同时作为暂存单元。

**伪代码：**

```c
void InsertSort(ElementType A[], int n) {
    int i, j;
    // 从第2个元素开始遍历 (假设下标1开始存储数据，下标0为哨兵)
    for (i = 2; i <= n; i++) {
        if (A[i] < A[i-1]) {    // 若 A[i] 小于有序区最后一个元素，需插入
            A[0] = A[i];        // 1. 设置哨兵
            A[i] = A[i-1];      // 2. 后移一位
          
            // 3. 从后往前查找插入位置
            for (j = i-2; A[0] < A[j]; --j) {
                A[j+1] = A[j];  // 记录后移
            }
            A[j+1] = A[0];      // 4. 插入到正确位置
        }
    }
}
```

* **课件案例分析**：`49, 38, 65, 97, 76...`
  * `i=2` (38): 38 < 49，49后移，38插头。 -> `[38, 49], 65...`
  * `i=3` (65): 65 > 49，不移动。 -> `[38, 49, 65], 97...`

#### 2. 希尔排序 (Shell Sort)

* **思路**：**缩小增量排序**。将序列按增量 $d$ 分组，对每组进行直接插入排序，然后减小 $d$ 重复，直到 $d=1$。
* **目的**：让序列“基本有序”，从而让最后一次 $d=1$ 的插入排序非常快。

**伪代码：**

```c
void ShellSort(ElementType A[], int n) {
    int i, j, d;
    // 增量 d 逐步减半，直到 1
    for (d = n/2; d >= 1; d = d/2) {
      
        // 对每一组进行直接插入排序
        // 注意：这里是一个交替进行的写法，i++ 意味着遍历所有组
        for (i = d + 1; i <= n; ++i) {
            if (A[i] < A[i-d]) {
                A[0] = A[i];    // 暂存
              
                // 在子序列中查找位置
                for (j = i-d; j > 0 && A[0] < A[j]; j -= d) {
                    A[j+d] = A[j]; // 后移，跨度为 d
                }
                A[j+d] = A[0];  // 插入
            }
        }
    }
}
```

---

### 10.2 交换排序类 (Exchange Sort)

核心思想：**两两比较，逆序则交换**。

#### 1. 冒泡排序 (Bubble Sort)

* **思路**：每一趟将最大的元素“浮”到最后。

**伪代码：**

```c
void BubbleSort(ElementType A[], int n) {
    int i, j, temp;
    bool flag; // 优化：如果一趟没发生交换，说明已有序
  
    for (i = 1; i < n; i++) { // 进行 n-1 趟
        flag = false;
        // 从前向后扫描，边界逐次减小
        for (j = 1; j <= n - i; j++) { 
            if (A[j] > A[j+1]) { // 若逆序，交换
                swap(A[j], A[j+1]);
                flag = true;
            }
        }
        if (flag == false) break; // 提前结束
    }
}
```

#### 2. 快速排序 (Quick Sort) —— **必考重点**

* **思路**：**分治法**。选基准 (pivot)，将比基准小的放左边，大的放右边（Partition过程），然后递归。
* **Partition实现**：课件描述的是经典的“双指针交换法”。

**伪代码：**

```c
// 核心划分函数：返回基准值最终所在的位置
int Partition(ElementType A[], int low, int high) {
    ElementType pivot = A[low]; // 1. 选取第一个元素为基准
  
    while (low < high) {
        // 2. High指针左移：找比 pivot 小的
        while (low < high && A[high] >= pivot) high--;
        A[low] = A[high];       // 移到左端(覆盖pivot原位置或上一次low的位置)
      
        // 3. Low指针右移：找比 pivot 大的
        while (low < high && A[low] <= pivot) low++;
        A[high] = A[low];       // 移到右端
    }
  
    A[low] = pivot; // 4. 基准归位
    return low;     // 返回基准位置
}

// 主递归函数
void QuickSort(ElementType A[], int low, int high) {
    if (low < high) {
        int pivotPos = Partition(A, low, high); // 划分
        QuickSort(A, low, pivotPos - 1);        // 递归左半部分
        QuickSort(A, pivotPos + 1, high);       // 递归右半部分
    }
}
```

* **课件案例分析**：`49, 38, 65, 97, 76, 13, 27, 52`
  * 基准 `49`。
  * `high` 找比49小的 `27`，移到左边；`low` 找比49大的 `65`，移到右边...
  * 一趟结束后：`27, 38, 13, [49], 76, 97, 65, 52`。49已就位。

---

### 10.3 选择排序类 (Selection Sort)

核心思想：**每一趟在后面 $n-i$ 个中选出最小的，与第 $i$ 个交换**。

#### 1. 简单选择排序 (Simple Selection Sort)

**伪代码：**

```c
void SelectSort(ElementType A[], int n) {
    int i, j, min_idx;
    for (i = 1; i < n; i++) {
        min_idx = i; // 假设当前第i个是最小的
      
        // 在后面找更小的
        for (j = i + 1; j <= n; j++) {
            if (A[j] < A[min_idx]) {
                min_idx = j;
            }
        }
      
        // 如果找到了更小的，交换
        if (min_idx != i) {
            swap(A[i], A[min_idx]);
        }
    }
}
```

#### 2. 堆排序 (Heap Sort) —— **难点**

* **思路**：将数组看作**完全二叉树**。
    1. **建堆**：从最后一个非叶子节点开始，向下调整 (`HeapAdjust`)。
    2. **排序**：输出堆顶（交换到数组末尾），然后对剩余部分重新向下调整。
* **注意**：升序排序通常建立**大顶堆**（最大值在根，换到数组末尾后，末尾就是最大值）。

**伪代码：**

```c
// 核心：向下调整 (筛选)
// 假设 start 结点的左右子树已经是堆，将 start 下沉到合适位置
void HeapAdjust(ElementType A[], int start, int end) {
    ElementType temp = A[start];
    // j 初始指向左孩子 (2*start)
    for (int j = 2 * start; j <= end; j *= 2) {
        // 让 j 指向左右孩子中较大的那个
        if (j < end && A[j] < A[j+1]) j++; 
      
        if (temp >= A[j]) break; // 根比孩子都大，不需要调整了
      
        A[start] = A[j]; // 孩子上移
        start = j;       // 继续向下层比较
    }
    A[start] = temp; // 放入最终位置
}

void HeapSort(ElementType A[], int n) {
    // 1. 初建堆 (大顶堆)
    // 从最后一个非叶子节点 (n/2) 开始
    for (int i = n / 2; i > 0; i--) {
        HeapAdjust(A, i, n);
    }
  
    // 2. 排序输出
    for (int i = n; i > 1; i--) {
        swap(A[1], A[i]);      // 把堆顶(最大值)交换到末尾
        HeapAdjust(A, 1, i-1); // 把剩余的 i-1 个元素重新调整为堆
    }
}
```

---

### 10.4 归并排序 (Merge Sort)

核心思想：**分而治之，将两个有序表合并成一个**。

**伪代码：**

```c
// 合并两个有序序列 A[low..mid] 和 A[mid+1..high] 到 Temp
void Merge(ElementType A[], ElementType Temp[], int low, int mid, int high) {
    int i = low, j = mid + 1, k = low;
  
    // 比较两个序列的头，谁小取谁
    while (i <= mid && j <= high) {
        if (A[i] <= A[j]) Temp[k++] = A[i++];
        else              Temp[k++] = A[j++];
    }
  
    // 将剩余部分复制进去
    while (i <= mid)  Temp[k++] = A[i++];
    while (j <= high) Temp[k++] = A[j++];
  
    // 拷回原数组
    for (i = low; i <= high; i++) A[i] = Temp[i];
}

void MergeSort(ElementType A[], ElementType Temp[], int low, int high) {
    if (low < high) {
        int mid = (low + high) / 2;
        MergeSort(A, Temp, low, mid);      // 左边有序
        MergeSort(A, Temp, mid + 1, high); // 右边有序
        Merge(A, Temp, low, mid, high);    // 合并
    }
}
```

---

### 10.5 总结：代码层面的对比

| 算法 | 核心操作 (伪代码关键词) | 复杂度 | 稳定性 |
| :--- | :--- | :--- | :--- |
| **直接插入** | `A[0]=temp`, `A[j+1]=A[j]` (后移) | $O(n^2)$ | 稳定 |
| **冒泡** | `swap(A[j], A[j+1])` (相邻交换) | $O(n^2)$ | 稳定 |
| **快速** | `Partition`, `pivot` (基准划分) | $O(n \log n)$ | **不稳定** |
| **简单选择** | `min_idx`, `swap` (远距离交换) | $O(n^2)$ | **不稳定** |
| **堆排序** | `HeapAdjust` (向下调整/筛选) | $O(n \log n)$ | **不稳定** |
| **归并** | `Merge` (另开数组复制) | $O(n \log n)$ | 稳定 |

**复习建议：**
重点默写 **QuickSort (快速排序)** 的 `Partition` 函数和 **HeapSort (堆排序)** 的 `HeapAdjust` 函数。这两个是考试中代码填空或算法设计题最高频的考点。
